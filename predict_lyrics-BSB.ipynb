{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "start_time_0 = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lyrics = open('BSB.txt').read()\n",
    "lyrics = lyrics.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36518"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convert char to num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "chars = [i for i in sorted(set(lyrics))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "char_num = dict((char, num) for num, char in enumerate(chars))\n",
    "num_char = dict((num, char) for num, char in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lyrics_num = [char_num[i] for i in lyrics]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alphabet = len(char_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### create sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def chop_to_sequence(seq, lyrics_num):\n",
    "    \"\"\"\n",
    "    chop lyrics_num into segments with length seq\n",
    "    return list of segments\n",
    "    \"\"\"\n",
    "    lyrics_arr = np.asarray(lyrics_num)\n",
    "    lyrics_arr = lyrics_arr / float(alphabet)\n",
    "    segments = []\n",
    "    next_char = []\n",
    "    for i in range(0, len(lyrics_num)-seq):\n",
    "        segment = lyrics_arr[i:i+seq]\n",
    "        segments.append(segment)\n",
    "        next_char.append(lyrics_num[i+seq])\n",
    "\n",
    "    print(\"segment length:\", seq)\n",
    "    print('number of segments:', len(segments))\n",
    "    print(\"chars in lyrics:\", len(lyrics))\n",
    "    print(\"\")\n",
    "    \n",
    "    segments = np.reshape(segments, (len(segments),seq,1))\n",
    "    next_char = np_utils.to_categorical(next_char)\n",
    "    \n",
    "    return segments, next_char\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_time(start_time):\n",
    "    print((time()-start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment length: 30\n",
      "number of segments: 36488\n",
      "chars in lyrics: 36518\n",
      "\n",
      "0.001679245630900065\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "X_all, y_all = chop_to_sequence(30, lyrics_num)\n",
    "print_time(start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_next_n(n):\n",
    "    \"\"\"\n",
    "    predict next n char from random seed\n",
    "    \"\"\"\n",
    "    start = np.random.randint(0, len(X))\n",
    "    seed = lyrics[start:start+X.shape[1]]\n",
    "    pattern = X[start]\n",
    "    \n",
    "    chars=[]\n",
    "    for i in range(n):\n",
    "        pred_num = model.predict_classes(np.reshape(pattern,(1,pattern.shape[0],1)), verbose=False)\n",
    "        #pred_num = np.argmax(pred_arr)\n",
    "        pred_char = num_char[pred_num[0]]\n",
    "        \n",
    "        chars.append(pred_char)\n",
    "        pattern = np.append(pattern, pred_num/float(alphabet))\n",
    "        pattern = pattern[1:]\n",
    "        #print(pred_arr, pred_num, pred_char, pattern)\n",
    "    print(\"Seed:\", seed)\n",
    "    print(\"Generated:\", \"\".join(chars))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X=X_all\n",
    "y=y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(alphabet, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(alphabet))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29190 samples, validate on 7298 samples\n",
      "Epoch 1/10\n",
      "29184/29190 [============================>.] - ETA: 0s - loss: 3.0594 - acc: 0.1669Epoch 00000: loss improved from inf to 3.05949, saving model to weights-improvement-00-3.0595-bigger.hdf5\n",
      "29190/29190 [==============================] - 107s - loss: 3.0595 - acc: 0.1668 - val_loss: 3.0197 - val_acc: 0.1750\n",
      "Epoch 2/10\n",
      "29184/29190 [============================>.] - ETA: 0s - loss: 3.0352 - acc: 0.1668Epoch 00001: loss improved from 3.05949 to 3.03515, saving model to weights-improvement-01-3.0351-bigger.hdf5\n",
      "29190/29190 [==============================] - 107s - loss: 3.0351 - acc: 0.1668 - val_loss: 2.9985 - val_acc: 0.1750\n",
      "Epoch 3/10\n",
      "29184/29190 [============================>.] - ETA: 0s - loss: 2.9359 - acc: 0.1851Epoch 00002: loss improved from 3.03515 to 2.93571, saving model to weights-improvement-02-2.9357-bigger.hdf5\n",
      "29190/29190 [==============================] - 104s - loss: 2.9357 - acc: 0.1852 - val_loss: 2.8519 - val_acc: 0.2217\n",
      "Epoch 4/10\n",
      "29184/29190 [============================>.] - ETA: 0s - loss: 2.8339 - acc: 0.2158Epoch 00003: loss improved from 2.93571 to 2.83420, saving model to weights-improvement-03-2.8342-bigger.hdf5\n",
      "29190/29190 [==============================] - 104s - loss: 2.8342 - acc: 0.2158 - val_loss: 2.7908 - val_acc: 0.2223\n",
      "Epoch 5/10\n",
      "29184/29190 [============================>.] - ETA: 0s - loss: 2.7826 - acc: 0.2251Epoch 00004: loss improved from 2.83420 to 2.78262, saving model to weights-improvement-04-2.7826-bigger.hdf5\n",
      "29190/29190 [==============================] - 106s - loss: 2.7826 - acc: 0.2252 - val_loss: 2.7534 - val_acc: 0.2358\n",
      "Epoch 6/10\n",
      "29184/29190 [============================>.] - ETA: 0s - loss: 2.7449 - acc: 0.2301Epoch 00005: loss improved from 2.78262 to 2.74503, saving model to weights-improvement-05-2.7450-bigger.hdf5\n",
      "29190/29190 [==============================] - 103s - loss: 2.7450 - acc: 0.2301 - val_loss: 2.7316 - val_acc: 0.2435\n",
      "Epoch 7/10\n",
      "29184/29190 [============================>.] - ETA: 0s - loss: 2.7083 - acc: 0.2422Epoch 00006: loss improved from 2.74503 to 2.70836, saving model to weights-improvement-06-2.7084-bigger.hdf5\n",
      "29190/29190 [==============================] - 106s - loss: 2.7084 - acc: 0.2422 - val_loss: 2.7045 - val_acc: 0.2501\n",
      "Epoch 8/10\n",
      "29184/29190 [============================>.] - ETA: 0s - loss: 2.6734 - acc: 0.2490Epoch 00007: loss improved from 2.70836 to 2.67352, saving model to weights-improvement-07-2.6735-bigger.hdf5\n",
      "29190/29190 [==============================] - 103s - loss: 2.6735 - acc: 0.2490 - val_loss: 2.6902 - val_acc: 0.2540\n",
      "Epoch 9/10\n",
      "29184/29190 [============================>.] - ETA: 0s - loss: 2.6465 - acc: 0.2509Epoch 00008: loss improved from 2.67352 to 2.64649, saving model to weights-improvement-08-2.6465-bigger.hdf5\n",
      "29190/29190 [==============================] - 102s - loss: 2.6465 - acc: 0.2510 - val_loss: 2.6604 - val_acc: 0.2601\n",
      "Epoch 10/10\n",
      "29184/29190 [============================>.] - ETA: 0s - loss: 2.6200 - acc: 0.2549Epoch 00009: loss improved from 2.64649 to 2.62023, saving model to weights-improvement-09-2.6202-bigger.hdf5\n",
      "29190/29190 [==============================] - 103s - loss: 2.6202 - acc: 0.2548 - val_loss: 2.6491 - val_acc: 0.2492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x126fb3b00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "start_time = time()\n",
    "model.fit(X, y, epochs=10, batch_size=64, callbacks= callbacks_list, verbose= True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.12507123549779\n"
     ]
    }
   ],
   "source": [
    "print_time(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: o worlds apart\n",
      "can't reach to \n",
      "Generated: bot ie the the the why aut ie she the the why aut ie she the the why aut ie she the the why aut ie s\n"
     ]
    }
   ],
   "source": [
    "predict_next_n(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: jam\n",
      "\n",
      "jam on 'cause backstreets\n",
      "Generated:  to mene i lane to toat you ao\n",
      "Seed:  than life\n",
      "\n",
      "yeah, every time w\n",
      "Generated: ou aod i want you back toar yo\n",
      "Seed: history\n",
      "as long as you're here\n",
      "Generated:  i lane it toer you aod i lane\n",
      "Seed: you)\n",
      "but still no (still no wo\n",
      "Generated: u aod ioer to mene it toer you\n",
      "Seed: \n",
      "(phone hang-up)\n",
      "\n",
      "let me tell \n",
      "Generated: you loet you aack the the touh\n",
      "Seed:  wish that i could believe\n",
      "tha\n",
      "Generated: t you aod i want you back toar\n",
      "Seed: \n",
      "\n",
      "ain't nothin' but a heartach\n",
      "Generated:  toat you aod i want you back \n",
      "Seed:  would blend 'cause we stayed \n",
      "Generated: back\n",
      "that i lane it toer you a\n",
      "Seed: mistake\n",
      "tell me why\n",
      "i never wa\n",
      "Generated: an touh me the the wour aut me\n",
      "Seed: h) (rock your body)\n",
      "rock your \n",
      "Generated: bod i lane to toat you aod i w\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    predict_next_n(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29190 samples, validate on 7298 samples\n",
      "Epoch 1/50\n",
      "29190/29190 [==============================] - 104s - loss: 2.5971 - acc: 0.2559 - val_loss: 2.6270 - val_acc: 0.2506\n",
      "Epoch 2/50\n",
      "29190/29190 [==============================] - 106s - loss: 2.5727 - acc: 0.2565 - val_loss: 2.6159 - val_acc: 0.2577\n",
      "Epoch 3/50\n",
      "29190/29190 [==============================] - 104s - loss: 2.5499 - acc: 0.2598 - val_loss: 2.6017 - val_acc: 0.2503\n",
      "Epoch 4/50\n",
      "29190/29190 [==============================] - 104s - loss: 2.5300 - acc: 0.2624 - val_loss: 2.5963 - val_acc: 0.2545\n",
      "Epoch 5/50\n",
      "29190/29190 [==============================] - 105s - loss: 2.5099 - acc: 0.2681 - val_loss: 2.5714 - val_acc: 0.2613\n",
      "Epoch 6/50\n",
      "29190/29190 [==============================] - 104s - loss: 2.4899 - acc: 0.2751 - val_loss: 2.5636 - val_acc: 0.2543\n",
      "Epoch 7/50\n",
      "29190/29190 [==============================] - 106s - loss: 2.4693 - acc: 0.2796 - val_loss: 2.5512 - val_acc: 0.2547\n",
      "Epoch 8/50\n",
      "29190/29190 [==============================] - 104s - loss: 2.4489 - acc: 0.2855 - val_loss: 2.5313 - val_acc: 0.2686\n",
      "Epoch 9/50\n",
      "29190/29190 [==============================] - 106s - loss: 2.4308 - acc: 0.2883 - val_loss: 2.5199 - val_acc: 0.2713\n",
      "Epoch 10/50\n",
      "29190/29190 [==============================] - 105s - loss: 2.4117 - acc: 0.2948 - val_loss: 2.5102 - val_acc: 0.2787\n",
      "Epoch 11/50\n",
      "29190/29190 [==============================] - 105s - loss: 2.3915 - acc: 0.3034 - val_loss: 2.5008 - val_acc: 0.2777\n",
      "Epoch 12/50\n",
      "29190/29190 [==============================] - 105s - loss: 2.3748 - acc: 0.3083 - val_loss: 2.4902 - val_acc: 0.2908\n",
      "Epoch 13/50\n",
      "29190/29190 [==============================] - 103s - loss: 2.3553 - acc: 0.3143 - val_loss: 2.4879 - val_acc: 0.2862\n",
      "Epoch 14/50\n",
      "29190/29190 [==============================] - 105s - loss: 2.3387 - acc: 0.3196 - val_loss: 2.4789 - val_acc: 0.2946\n",
      "Epoch 15/50\n",
      "29190/29190 [==============================] - 105s - loss: 2.3200 - acc: 0.3277 - val_loss: 2.4773 - val_acc: 0.2925\n",
      "Epoch 16/50\n",
      "29190/29190 [==============================] - 104s - loss: 2.3026 - acc: 0.3354 - val_loss: 2.4649 - val_acc: 0.2920\n",
      "Epoch 17/50\n",
      "29190/29190 [==============================] - 103s - loss: 2.2847 - acc: 0.3403 - val_loss: 2.4566 - val_acc: 0.2932\n",
      "Epoch 18/50\n",
      "29190/29190 [==============================] - 104s - loss: 2.2681 - acc: 0.3458 - val_loss: 2.4447 - val_acc: 0.3015\n",
      "Epoch 19/50\n",
      "29190/29190 [==============================] - 106s - loss: 2.2540 - acc: 0.3517 - val_loss: 2.4439 - val_acc: 0.2980\n",
      "Epoch 20/50\n",
      "29190/29190 [==============================] - 106s - loss: 2.2367 - acc: 0.3591 - val_loss: 2.4386 - val_acc: 0.3008\n",
      "Epoch 21/50\n",
      "29190/29190 [==============================] - 104s - loss: 2.2204 - acc: 0.3628 - val_loss: 2.4360 - val_acc: 0.2995\n",
      "Epoch 22/50\n",
      "29190/29190 [==============================] - 103s - loss: 2.2025 - acc: 0.3684 - val_loss: 2.4311 - val_acc: 0.3080\n",
      "Epoch 23/50\n",
      "26944/29190 [==========================>...] - ETA: 7s - loss: 2.1880 - acc: 0.3763"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4ffc6b6dba44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/envs/dl/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Applications/anaconda/envs/dl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/dl/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/dl/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Applications/anaconda/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/dl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "model.fit(X, y, epochs=50, batch_size=64, verbose= True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print_time(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predict_next_n(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
